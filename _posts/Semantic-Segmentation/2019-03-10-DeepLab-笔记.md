---
layout: post
title: DeepLab 笔记
category: 语义分割
tags: deeplab
description:
---

## 一、背景

DCNN 存在的问题：

1. 多次下采样使输出信号分辨率变小 —— 空洞卷积
2. 池化对输入变换具有内在空间不变性 —— CRF

## 二、空洞卷积

**作用：**

- 保证感受野不发生变化
- 得到密集的 feature map

**卷积核：**

$$new\_kernel = kernel + \left(kernel - 1 \right) \times \left( dilation - 1\right)$$

**输出大小：**

$$output = \left \lfloor \frac{in - kernel - \left( kernel -1\right) \times \left( dilation -1 \right) +2\times padding}{stride} \right \rfloor + 1$$

**感受野：**

$$RF_{l} = RF_{l-1} + \left( kernel\_size_{l} - 1\right) \times feature\_stride_{l-1} \times dilation_{l}$$

## 三、条件随机场（CRF）

**作用：**

- 精细化边缘信息

DeepLab 后面接了一个全连接条件随机场 (Fully-Connected Conditional Random Fields) 对分割边界进行 refine label map。CRF 经常用于 pixel-wise 的 label 预测。把像素的 label 作为随机变量，像素与像素间的关系作为边，即构成了一个条件随机场且能够获得全局观测时，CRF 便可以对这些 label 进行建模。全局观测通常就是输入图像。

<center>

<img src="https://raw.githubusercontent.com/chiemon/chiemon.github.io/master/img/DeepLab/1.png">

</center>

令随机变量 $X_{i}$ 是像素 i 的标签，$X_{i} \in L = l_{1}，l_{2}，\cdots，l_{L}$，令变量 $X$ 是由 $X_{1}，X_{2}，\cdots，X_{N}$ 组成的随机向量，N 就是图像的像素个数。

假设图 $G = \left(V，E\right)$，其中 $V = X_{1}，X_{2}，\cdots，X_{N}$，全局观测为$I$。条件随机场符合吉布斯分布，$\left(I，X\right)$ 可以被模型为 CRF，

$$P \left(X = x \vert I\right) = \frac{1}{Z \left(I\right) \exp \left(-E \left(x \vert I\right)\right)}$$

在全连接的CRF模型中，标签 x 的能量可以表示为：

$$E\left(x\right)=\sum_{i} \theta \left(x_{i}\right) + \sum_{ij} \theta_{i} j\left(x_{i},x_{j}\right)$$

其中，$\theta_{i}\left(x_{i}\right)$ 是一元能量项，代表着将像素 i 分成 label $x_{i}$ 的能量，二元能量项 $\varphi_{p} \left(x_{i},x_{j}\right)$ 是对像素点 i, j 同时分割成 $x_{i}，x_{j}$ 的能量。二元能量项表述像素点与像素点之间的关系，鼓励相似像素分配相同的标签，而相差较大的像素分配不同的标签，而这个“距离”的定义与颜色值和实际相对距离有关。所以这样 CRF 能够使图片尽量在边界处分割。最小化上面的能量就可以找到最有可能的分割。而全连接条件随机场的不同就在于，二元势函数描述的是每一个像素与其他所有像素的关系，所以叫“全连接”。具体来说，在 DeepLab 中一元能量项直接来自于前端 FCN 的输出，计算方式如下：

$$\theta_{i} \left(x_{i}\right) = -\log P\left(x_{i}\right)$$

而二元能量项的计算方式如下：

$$\theta_{i}j\left ( x_{i},x_{j} \right ) = \mu j\left ( x_{i},x_{j} \right )\left [ \omega_{1} \exp \left ( -\frac{\left \Vert p_{i} - p_{j} \right \Vert^{2}}{2 \sigma_{\alpha}^{2}} -\frac{\left \Vert I_{i} - I_{j} \right \Vert^{2}}{2 \sigma_{\beta}^{2}}\right ) + \omega_{2} \exp \left ( -\frac{\left \Vert p_{i} - p_{j} \right \Vert^{2}}{2 \sigma _{\gamma}^{2}} \right ) \right ]$$

其中，$\mu \left ( x_{i},x_{j} \right ) = 1$, 当 $i \neq j$ 时，其他的值为0。也就是说当标签不同是，才有惩罚。剩余表达式是在不同特征空间的两个高斯核函数，第一个基于双边高斯函数基于像素位置 p 和 RGB 值 I，强制相似 RGB 和超参数 $\sigma_{\alpha},\sigma_{\beta},\sigma _{\gamma}$ 控制高斯核函数的权重。

## 四、DeepLab V1

关键技术

- dilation convolution
- CRF

### 网络结构

<center>

<img src="https://raw.githubusercontent.com/chiemon/chiemon.github.io/master/img/DeepLab/2.png">

</center>

上图为 VGG16 网络，DeepLab v1 在此网络上修改。

<center>

<img src="https://raw.githubusercontent.com/chiemon/chiemon.github.io/master/img/DeepLab/3.png">

</center>

1. 全连接层替换为卷积层；

2. 去除降采样：将 pool4 和 pool5 层的 stride 由 2 改为 1，使得 VGG16 网络总的 stride 由原来的 32 变成 8。

3. 引入空洞卷积：保证感受野不变
- pool4 stride 改变，后面的层感受野都会随之改变；
- conv5_1，conv5_2，conv5_3，pool5 膨胀系数由 1 改为 2；
- conv14 即 由第一个全连接层改的卷积层，膨胀系数由 1 改为 4；

4. 将最后一层的类别 1000 的分类器替换为类别 21 的一个，损失函数是卷积 output map 上每个空间位置交叉熵的求和；

5. 提升训练速度：

- 减小kernel：第一个全连接层会有 4096 个大小为 7x7 的 filters，这大大增加了计算的难度。该文减少第一个全连接层 filter 的空间尺寸（3x3），但也相对应的减少了网络的感受野，减少了 2 到 3 倍的计算时间。

- 减少channel：把 FC6 输出的 feature map 从 4096 减少到 1024

该文首先利用 DCNN 的识别能力，后接全连接的 CRF 来提高位置的准确性，通常，CRF 包含相邻节点的能量项，有利于将相同的标签分配到空间上相近的像素。本质上，short-range CRF 的作用是清除由基于局部手工设计分类器产生的错误预测。相比弱分类器，DCNN 得到的 score maps 更加平滑，此时，再使用 short-range CRF可能是有害的，因为目的不是为了平滑边界而是回复局部细节，因为经过 DCNN 后已经很平滑了。为了解决 short-range CRF 的弊端，引入了全连接CRF。

### 实验 & 测试

- 在ImageNet上预训练的VGG16权重上做finetune
- CRF是后期处理，不参与训练
- 测试时，对特征提取后得到的 feature map 进行双线性插值，恢复到原图尺寸，然后再进行 CRF 处理。

## 五、DeepLab V2

### 关键技术

- dilation convolution
- ASPP
- CRF
- poly

### 网络结构

本文对 VGG16，ResNe-101 进行改进：

- 将全连接层变为卷积层;
- 将DCNN最后几个maxpooling去掉；
- 在后续的卷积层中添加更高 sample rate 的空洞卷积，增加特征图的分辨率；
- 对一张图片平行的使用不同 sample rate 的空洞卷积层（ASPP），增强感受野；
- 应用双线性插值将 score map 还原为原图大小;
- 全连接的 CRF，改善模型对边界的分割;

虽然CRF作为后处理的手段，但该文将CRF的 mean-filed 推理步骤进行转化，并添加到end-to-end可训练的前向网络中。

DeepLab v2 相比 DeepLab v1 的改进：对多尺寸的图片分割效果更好，引入 ASPP，用 ResNet 作为 backbone，实现比 VGG16 更好的效果。

### ASPP

为了解决分割中的多尺寸问题，该文实验了两种方法：

1. 采用传统的方法，在训练和测试时，从 DCNN 中抽取多层（这里使三层）feature map，通过双线性插值恢复为原图尺寸，然后将其进行融合，这么做确实有效果，但是增加了DCNN的计算量。

2. 对一张图片上通过平行的进行不同尺寸的空洞卷积操作，间接的得到多尺度特性，不同 sample rate 提取的特征经过单独的后处理和融合进而生成最终的结果。采用的即 ASPP 模型，如下图。

<center>

<img src="https://raw.githubusercontent.com/chiemon/chiemon.github.io/master/img/DeepLab/4.png">

</center>

ASPP 各个空洞卷积分支采样后结果最后融合到一起（通道相同，做像素加）。

### 实验 & 测试

将 VGG-16 和 ResNet-101 处理成分割网络。损失函数是 CNN 输出 feature map（缩小为8倍）后空间位置交叉熵的和，使用 SGD 优化算法，在 PASCAL VOC 2012, PASCAL-Context, PASCALPerson-Part,和 Cityscapes 上进行实验。

**实验上的改进：**

- 训练时不同的学习策略。
- ASPP
- 加深网络和多尺度处理
- 使用 poly 学习速率
- 调整 ASPP 中的rate: r={2,4,8,12} r={6,12,18,24}
- 将 VGG-16 换为 ResNet-101 使网络加深

<center>

<img src="https://raw.githubusercontent.com/chiemon/chiemon.github.io/master/img/DeepLab/5.png">

</center>

## DeepLab V3

### 网络结构

## DeepLab V3+

### 网络结构
