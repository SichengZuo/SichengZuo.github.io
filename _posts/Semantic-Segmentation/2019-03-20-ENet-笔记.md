---
layout: post
title: ENet 笔记
category: 语义分割
tags: enet
description:
---

**关键点**

- bottleneck
- BN + PRelU
- Spatial Dropout
- 只有 weights，无 bias

## 一、背景

许多移动应用需要实时语义分割模型。深度神经网络需要大量的浮点运算，导致运行时间长，从而降低了时效性。ENet，相比于 SegNet，在速度块，浮点计算量少，参数少，且有相似的精度。

## 二、网络结构

### 整体架构

<center>

<img src="https://raw.githubusercontent.com/chiemon/chiemon.github.io/master/img/ENet/1.png">

</center>

- initial：初始化模块，提升速度；
- Stage 1：encoder 阶段。包括 5 个 bottleneck，第一个 bottleneck 做下采样，后面 4 个重复的 bottleneck；
- Stage 2-3：encoder 阶段。stage2 的 bottleneck2.0 做了下采样，后面有时加空洞卷积，或分解卷积。stage3 没有下采样，其他都一样；
- Stage 4~5：属于 decoder 阶段；

### 初始化模块

<center>

<img src="https://raw.githubusercontent.com/chiemon/chiemon.github.io/master/img/ENet/2.png">

</center>

- Conv：3x3，stride 2，num 13
- Maxpooling：2x2，stride 2，num 3

将两边结果 concat 一起，合并成 16 通道，这样可以上来显著减少存储空间。

### bottleneck 模块

bottleneck 模块，基于 ResNet 思想。

1. 基本的 bottleneck

    <center>

    <img src="https://raw.githubusercontent.com/chiemon/chiemon.github.io/master/img/ENet/3.png">

    </center>

    - 第一个 1x1 卷积实现降维；
    - 第二个 1x1 卷积实现升维；
    - 使用 PReLU 激活函数，ReLU 降低了模型精度；
    - 元素级加法融合；

2. 下采样的 bottleneck

    <center>

    <img src="https://raw.githubusercontent.com/chiemon/chiemon.github.io/master/img/ENet/4.png">

    </center>

    - pool（2x2）提取上下文信息，保存 pooling indices；

3. 上采样的 bottleneck

    <center>

    <img src="https://raw.githubusercontent.com/chiemon/chiemon.github.io/master/img/ENet/5.png">

    </center>

    -  upsample 采用的是 SegNet 的方法进行上采样，结合下采样中的 pooling indices；



### 网络细节

- Encoder 阶段 Feature map 8 倍下采样；
- Encoder 和 Decoder 不是镜像对称的，网络的大部分实现 Encoder，较少部分实现 Decoder。Encoder 主要进行信息处理和过滤，而 Decoder 上采样编码器的输出，并进行细节微调；
- 整个网络中没有使用 bias，只有 weights。可减少内核调用和内存操作，因为cuDNN会使用单独的内核进行卷积和bias相加。这种方式对准确性没有任何影响；
- bottleneck 模块之间：在扩展分支上 bn 后 合并前添加 Spatial Dropout 正则化（bottleneck 2.0 之前 p=0.01，之后 p=0.1），再通过 prelu 连接下一个 bottleneck；

## 三、训练策略

- 优化器：Adam
- 两阶段训练策略：第一步只训练encoder，对输入做分类；再附加decoder训练
- 学习率：5e-4
- L2权重衰减：2e-4
- batch_size：10
- 使用自定义类别权重(a custom class weighing scheme)： $\omega _{class}= \frac{1}{ln(c+p_{class})}$
- 超参数c：1.02